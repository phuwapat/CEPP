{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pandas.api.types import is_object_dtype\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_28448\\2329999582.py:263: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(n=n_per_class, random_state=42))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backers_count               0\n",
      "blurb                       3\n",
      "converted_pledged_amount    0\n",
      "country                     0\n",
      "country_displayable_name    0\n",
      "                           ..\n",
      "country_freq                0\n",
      "cat_x_country_freq          0\n",
      "cat_country_share           0\n",
      "shortfall_severity_cls      0\n",
      "stretch_potential_cls       0\n",
      "Length: 99, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ver 1\n",
    "df = pd.read_csv(r\"D:\\coding\\CEPP\\combined_output\\all_combined.csv\")\n",
    "# df = df.iloc[:100_000].copy()\n",
    "# df = df.iloc[:900_000].copy()\n",
    "df = df.iloc[900_000:].copy()\n",
    "df = df.copy()\n",
    "original_df_count = len(df)\n",
    "\n",
    "def parse_json_field(json_str):\n",
    "    try:\n",
    "        return json.loads(json_str) if pd.notnull(json_str) else {}\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "#CATEGORY\n",
    "df[\"category_dict\"] = df[\"category\"].apply(parse_json_field)\n",
    "\n",
    "df[\"category_name\"] = df[\"category_dict\"].apply(lambda x: x.get(\"name\"))\n",
    "df[\"category_slug\"] = df[\"category_dict\"].apply(lambda x: x.get(\"slug\"))\n",
    "df[\"category_url\"] = df[\"category_dict\"].apply(lambda x: x.get(\"urls\", {}).get(\"web\", {}).get(\"discover\"))\n",
    "\n",
    "#CREATOR\n",
    "df[\"creator_dict\"] = df[\"creator\"].apply(parse_json_field)\n",
    "\n",
    "df[\"creator_id\"] = df[\"creator_dict\"].apply(lambda x: x.get(\"id\"))\n",
    "df[\"creator_name\"] = df[\"creator_dict\"].apply(lambda x: x.get(\"name\"))\n",
    "df[\"creator_avatar_thumb\"] = df[\"creator_dict\"].apply(lambda x: x.get(\"avatar\", {}).get(\"thumb\"))\n",
    "df[\"creator_profile_url\"] = df[\"creator_dict\"].apply(lambda x: x.get(\"urls\", {}).get(\"web\", {}).get(\"user\"))\n",
    "df[\"creator_api_url\"] = df[\"creator_dict\"].apply(lambda x: x.get(\"urls\", {}).get(\"api\", {}).get(\"user\"))\n",
    "\n",
    "#LOCATION\n",
    "df[\"location_dict\"] = df[\"location\"].apply(parse_json_field)\n",
    "\n",
    "df[\"location_id\"] = df[\"location_dict\"].apply(lambda x: x.get(\"id\"))\n",
    "df[\"location_name\"] = df[\"location_dict\"].apply(lambda x: x.get(\"name\"))\n",
    "df[\"location_slug\"] = df[\"location_dict\"].apply(lambda x: x.get(\"slug\"))\n",
    "df[\"location_short_name\"] = df[\"location_dict\"].apply(lambda x: x.get(\"short_name\"))\n",
    "df[\"location_country\"] = df[\"location_dict\"].apply(lambda x: x.get(\"country\"))\n",
    "df[\"location_state\"] = df[\"location_dict\"].apply(lambda x: x.get(\"state\"))\n",
    "df[\"location_url_web_discover\"] = df[\"location_dict\"].apply(lambda x: x.get(\"urls\", {}).get(\"web\", {}).get(\"discover\"))\n",
    "df[\"location_url_web_location\"] = df[\"location_dict\"].apply(lambda x: x.get(\"urls\", {}).get(\"web\", {}).get(\"location\"))\n",
    "\n",
    "#PROFILE\n",
    "df[\"profile_dict\"] = df[\"profile\"].apply(parse_json_field)\n",
    "df[\"profile_id\"] = df[\"profile_dict\"].apply(lambda x: x.get(\"id\"))\n",
    "df[\"profile_project_id\"] = df[\"profile_dict\"].apply(lambda x: x.get(\"project_id\"))\n",
    "df[\"profile_state\"] = df[\"profile_dict\"].apply(lambda x: x.get(\"state\"))\n",
    "\n",
    "#DATE\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], unit=\"s\")\n",
    "df[\"deadline\"] = pd.to_datetime(df[\"deadline\"], unit=\"s\")\n",
    "df[\"launched_at\"] = pd.to_datetime(df[\"launched_at\"], unit=\"s\")\n",
    "df[\"state_changed_at\"] = pd.to_datetime(df[\"state_changed_at\"], unit=\"s\")\n",
    "\n",
    "\n",
    "df = df[df[\"state\"].isin([\"successful\", \"failed\"])]\n",
    "df[\"state\"] = (df[\"state\"] == \"successful\").astype(int)\n",
    "\n",
    "df.drop(columns=[\"category\", \n",
    "                 \"category_dict\", \n",
    "                 \"creator\", \n",
    "                 \"creator_id\",\n",
    "                 \"creator_dict\",\n",
    "                 \"location\", \n",
    "                 \"location_dict\", \n",
    "                 \"profile\", \n",
    "                 \"profile_dict\", \n",
    "                 \"profile_id\",\n",
    "                 \"profile_project_id\",\n",
    "                 \"profile_state\",\n",
    "                 \"urls\",\n",
    "                 \"id\",\n",
    "                 \"slug\",\n",
    "                 \"usd_type\",\n",
    "                 \"source_url\",\n",
    "                 \"category_url\",\n",
    "                 \"creator_avatar_thumb\",\n",
    "                 \"creator_profile_url\",\n",
    "                 \"creator_api_url\",\n",
    "                 \"location_url_web_discover\",\n",
    "                 \"location_url_web_location\",\n",
    "                 \"location_slug\",\n",
    "                 \"location_id\",\n",
    "                 \"location_short_name\",\n",
    "                 \"currency_symbol\",\n",
    "                 \"currency_trailing_code\",\n",
    "                 \"disable_communication\",\n",
    "                 \"is_starrable\",\n",
    "                 \"is_in_post_campaign_pledging_phase\",\n",
    "                 \"is_disliked\",\n",
    "                 \"is_liked\",\n",
    "                 \"source_month\",\n",
    "                 \"source_file\",\n",
    "                 \"is_launched\"\n",
    "                 ], \n",
    "        inplace=True)\n",
    "\n",
    "\n",
    "df[\"success_rate\"] = df[\"percent_funded\"].round(0).astype(int)\n",
    "df[\"has_video\"] = df[\"video\"].notna().astype(int)\n",
    "df[\"has_photo\"] = df[\"photo\"].notna().astype(int)\n",
    "df[\"days_diff_created_at_deadline\"] = (df[\"deadline\"] - df[\"created_at\"]).dt.days\n",
    "df[\"days_diff_state_changed_at_launched_at\"] = (df[\"state_changed_at\"] - df[\"launched_at\"]).dt.days\n",
    "# df[\"days_diff_launched_at_deadline\"] = (df[\"deadline\"] - df[\"launched_at\"]).dt.days.clip(lower=1).astype(np.float32)\n",
    "df[\"days_diff_launched_at_deadline\"] = (df[\"deadline\"] - df[\"launched_at\"]).dt.days\n",
    "df[\"days_diff_launched_at_deadline_log\"] = np.log1p(df[\"days_diff_launched_at_deadline\"].clip(lower=1))\n",
    "df[\"too_short_or_long\"] = ((df[\"days_diff_launched_at_deadline\"] < 30) | (df[\"days_diff_launched_at_deadline\"] > 60)).astype(\"int8\")\n",
    "df[\"name_len\"] = df[\"name\"].astype(str).str.len()\n",
    "df[\"blurb_len\"] = df[\"blurb\"].astype(str).str.len()\n",
    "\n",
    "df[\"year_created_at\"] = df[\"created_at\"].dt.year\n",
    "df[\"month_created_at\"] = df[\"created_at\"].dt.month\n",
    "df[\"day_created_at\"] = df[\"created_at\"].dt.day\n",
    "\n",
    "df[\"created_at_mon_sin\"] = np.sin(2 * np.pi * (df[\"month_created_at\"] - 1) / 12)\n",
    "df[\"created_at_mon_cos\"] = np.cos(2 * np.pi * (df[\"month_created_at\"] - 1) / 12)\n",
    "\n",
    "df[\"created_at_dom_sin\"] = np.sin(2 * np.pi * (df[\"day_created_at\"] - 1) / 31)\n",
    "df[\"created_at_dom_cos\"] = np.cos(2 * np.pi * (df[\"day_created_at\"] - 1) / 31)\n",
    "\n",
    "df[\"year_deadline\"] = df[\"deadline\"].dt.year\n",
    "df[\"month_deadline\"] = df[\"deadline\"].dt.month\n",
    "df[\"day_deadline\"] = df[\"deadline\"].dt.day\n",
    "\n",
    "df[\"deadline_mon_sin\"] = np.sin(2 * np.pi * (df[\"month_deadline\"] - 1) / 12)\n",
    "df[\"deadline_mon_cos\"] = np.cos(2 * np.pi * (df[\"month_deadline\"] - 1) / 12)\n",
    "\n",
    "df[\"deadline_dom_sin\"] = np.sin(2 * np.pi * (df[\"day_deadline\"] - 1) / 31)\n",
    "df[\"deadline_dom_cos\"] = np.cos(2 * np.pi * (df[\"day_deadline\"] - 1) / 31)\n",
    "\n",
    "df[\"year_state_changed_at\"] = df[\"state_changed_at\"].dt.year\n",
    "df[\"month_state_changed_at\"] = df[\"state_changed_at\"].dt.month\n",
    "df[\"day_state_changed_at\"] = df[\"state_changed_at\"].dt.day\n",
    "\n",
    "df[\"state_changed_at_mon_sin\"] = np.sin(2 * np.pi * (df[\"month_state_changed_at\"] - 1) / 12)\n",
    "df[\"state_changed_at_mon_cos\"] = np.cos(2 * np.pi * (df[\"month_state_changed_at\"] - 1) / 12)\n",
    "\n",
    "df[\"state_changed_at_dom_sin\"] = np.sin(2 * np.pi * (df[\"day_state_changed_at\"] - 1) / 31)\n",
    "df[\"state_changed_at_dom_cos\"] = np.cos(2 * np.pi * (df[\"day_state_changed_at\"] - 1) / 31)\n",
    "\n",
    "df[\"year_launched_at\"] = df[\"launched_at\"].dt.year\n",
    "df[\"month_launched_at\"] = df[\"launched_at\"].dt.month\n",
    "df[\"day_launched_at\"] = df[\"launched_at\"].dt.day\n",
    "\n",
    "df[\"launched_at_mon_sin\"] = np.sin(2 * np.pi * (df[\"month_launched_at\"] - 1) / 12)\n",
    "df[\"launched_at_mon_cos\"] = np.cos(2 * np.pi * (df[\"month_launched_at\"] - 1) / 12)\n",
    "\n",
    "df[\"launched_at_dom_sin\"] = np.sin(2 * np.pi * (df[\"day_launched_at\"] - 1) / 31)\n",
    "df[\"launched_at_dom_cos\"] = np.cos(2 * np.pi * (df[\"day_launched_at\"] - 1) / 31)\n",
    "\n",
    "prep = (df[\"launched_at\"] - df[\"created_at\"]).dt.total_seconds() / 86400.0\n",
    "df[\"prep_days\"] = prep.clip(lower=0)\n",
    "df[\"launch_dow\"]    = df[\"launched_at\"].dt.dayofweek \n",
    "df[\"deadline_dow\"]    = df[\"deadline\"].dt.dayofweek \n",
    "\n",
    "category_mapping = {\n",
    "    # Art & Design\n",
    "    \"Art\": \"Art & Design\", \"Fine Art\": \"Art & Design\", \"Digital Art\": \"Art & Design\",\n",
    "    \"Illustration\": \"Art & Design\", \"Mixed Media\": \"Art & Design\", \"Painting\": \"Art & Design\",\n",
    "    \"Print\": \"Art & Design\", \"Printing\": \"Art & Design\", \"Graphic Design\": \"Art & Design\",\n",
    "    \"Typography\": \"Art & Design\", \"Conceptual Art\": \"Art & Design\", \"Installations\": \"Art & Design\",\n",
    "    \"Public Art\": \"Art & Design\", \"Design\": \"Art & Design\", \"Interactive Design\": \"Art & Design\",\n",
    "    \"Product Design\": \"Art & Design\", \"Fashion\": \"Art & Design\", \"Jewelry\": \"Art & Design\",\n",
    "    \"Pottery\": \"Art & Design\", \"Ceramics\": \"Art & Design\", \"Sculpture\": \"Art & Design\",\n",
    "    \"Textile\": \"Art & Design\", \"Embroidery\": \"Art & Design\", \"Weaving\": \"Art & Design\",\n",
    "    \"Knitting\": \"Art & Design\", \"Crochet\": \"Art & Design\", \"Stationery\": \"Art & Design\",\n",
    "    \"Letterpress\": \"Art & Design\", \"Art Books\": \"Art & Design\", \"Crafts\": \"Art & Design\",\n",
    "    \"DIY\": \"Art & Design\", \"DIY Electronics\": \"Art & Design\", \"Woodworking\": \"Art & Design\",\n",
    "    \"Candle\": \"Art & Design\", \"Glass\": \"Art & Design\", \"Metal\": \"Art & Design\",\n",
    "    \"Quilt\": \"Art & Design\", \"Fabrication Tools\": \"Art & Design\", \"Textiles\": \"Art & Design\",\n",
    "    \"Quilts\": \"Art & Design\",\n",
    "\n",
    "    # Music\n",
    "    \"Music\": \"Music\", \"Classical Music\": \"Music\", \"Electronic Music\": \"Music\",\n",
    "    \"Hip-Hop\": \"Music\", \"Indie Rock\": \"Music\", \"Jazz\": \"Music\", \"Latin\": \"Music\",\n",
    "    \"Pop\": \"Music\", \"Punk\": \"Music\", \"R&B\": \"Music\", \"Rock\": \"Music\", \"Blues\": \"Music\",\n",
    "    \"World Music\": \"Music\", \"Sound\": \"Music\", \"Music Videos\": \"Music\", \"Audio\": \"Music\",\n",
    "    \"Country & Folk\": \"Music\", \"Chiptune\": \"Music\", \"Dance\": \"Music\",\n",
    "\n",
    "    # Film, Video & Theater\n",
    "    \"Film & Video\": \"Film, Video & Theater\", \"Narrative Film\": \"Film, Video & Theater\",\n",
    "    \"Documentary\": \"Film, Video & Theater\", \"Shorts\": \"Film, Video & Theater\",\n",
    "    \"Animation\": \"Film, Video & Theater\", \"Video\": \"Film, Video & Theater\",\n",
    "    \"Video Art\": \"Film, Video & Theater\", \"Video Games\": \"Film, Video & Theater\",\n",
    "    \"Television\": \"Film, Video & Theater\", \"Theater\": \"Film, Video & Theater\",\n",
    "    \"Plays\": \"Film, Video & Theater\", \"Performances\": \"Film, Video & Theater\",\n",
    "    \"Performance Art\": \"Film, Video & Theater\", \"Musical\": \"Film, Video & Theater\",\n",
    "    \"Drama\": \"Film, Video & Theater\", \"Comedy\": \"Film, Video & Theater\",\n",
    "    \"Horror\": \"Film, Video & Theater\", \"Thrillers\": \"Film, Video & Theater\",\n",
    "    \"Webseries\": \"Film, Video & Theater\", \"Movie Theaters\": \"Film, Video & Theater\",\n",
    "    \"Festivals\": \"Film, Video & Theater\", \"Action\": \"Film, Video & Theater\",\n",
    "\n",
    "    # Books, Writing & Publishing\n",
    "    \"Books\": \"Books, Writing & Publishing\", \"Children's Books\": \"Books, Writing & Publishing\",\n",
    "    \"Comic Books\": \"Books, Writing & Publishing\", \"Comics\": \"Books, Writing & Publishing\",\n",
    "    \"Graphic Novels\": \"Books, Writing & Publishing\", \"Cookbooks\": \"Books, Writing & Publishing\",\n",
    "    \"Poetry\": \"Books, Writing & Publishing\", \"Fiction\": \"Books, Writing & Publishing\",\n",
    "    \"Nonfiction\": \"Books, Writing & Publishing\", \"Romance\": \"Books, Writing & Publishing\",\n",
    "    \"Science Fiction\": \"Books, Writing & Publishing\", \"Fantasy\": \"Books, Writing & Publishing\",\n",
    "    \"Anthologies\": \"Books, Writing & Publishing\", \"Zines\": \"Books, Writing & Publishing\",\n",
    "    \"Literary Journals\": \"Books, Writing & Publishing\", \"Literary Spaces\": \"Books, Writing & Publishing\",\n",
    "    \"Periodicals\": \"Books, Writing & Publishing\", \"Translations\": \"Books, Writing & Publishing\",\n",
    "    \"Publishing\": \"Books, Writing & Publishing\", \"Journalism\": \"Books, Writing & Publishing\",\n",
    "    \"Radio & Podcasts\": \"Books, Writing & Publishing\",\"Calendars\": \"Books, Writing & Publishing\",\n",
    "    \"Young Adult\": \"Books, Writing & Publishing\", \"Academic\": \"Books, Writing & Publishing\",\n",
    "\n",
    "    # Games & Toys\n",
    "    \"Games\": \"Games & Toys\", \"Tabletop Games\": \"Games & Toys\", \"Live Games\": \"Games & Toys\",\n",
    "    \"Mobile Games\": \"Games & Toys\", \"Gaming Hardware\": \"Games & Toys\", \"Toys\": \"Games & Toys\",\n",
    "    \"Playing Cards\": \"Games & Toys\", \"Puzzles\": \"Games & Toys\",\n",
    "\n",
    "    # Fashion & Wearables\n",
    "    \"Apparel\": \"Fashion & Wearables\", \"Ready-to-wear\": \"Fashion & Wearables\",\n",
    "    \"Childrenswear\": \"Fashion & Wearables\", \"Footwear\": \"Fashion & Wearables\",\n",
    "    \"Pet Fashion\": \"Fashion & Wearables\", \"Accessories\": \"Fashion & Wearables\",\n",
    "    \"Wearables\": \"Fashion & Wearables\", \"Couture\": \"Fashion & Wearables\",\n",
    "\n",
    "    # Food & Drink\n",
    "    \"Food\": \"Food & Drink\", \"Drinks\": \"Food & Drink\", \"Food Trucks\": \"Food & Drink\",\n",
    "    \"Vegan\": \"Food & Drink\", \"Small Batch\": \"Food & Drink\", \"Restaurants\": \"Food & Drink\",\n",
    "    \"Bakeries\": \"Food & Drink\", \"Farmers Markets\": \"Food & Drink\", \"Farms\": \"Food & Drink\",\n",
    "    \"Bacon\": \"Food & Drink\", \"Candles\": \"Food & Drink\", \"Farmer's Markets\": \"Food & Drink\",\n",
    "\n",
    "    # Technology & Software\n",
    "    \"Apps\": \"Technology & Software\", \"Software\": \"Technology & Software\", \"Web\": \"Technology & Software\",\n",
    "    \"Webcomics\": \"Technology & Software\", \"Robots\": \"Technology & Software\", \"Gadgets\": \"Technology & Software\",\n",
    "    \"Camera Equipment\": \"Technology & Software\", \"Hardware\": \"Technology & Software\",\n",
    "    \"Technology\": \"Technology & Software\", \"3D Printing\": \"Technology & Software\",\n",
    "    \"Space Exploration\": \"Technology & Software\",\n",
    "\n",
    "    # Community & Social Impact\n",
    "    \"Community Gardens\": \"Community & Social Impact\", \"Social Practice\": \"Community & Social Impact\",\n",
    "    \"Faith\": \"Community & Social Impact\", \"Civic Design\": \"Community & Social Impact\",\n",
    "    \"Family\": \"Community & Social Impact\", \"People\": \"Community & Social Impact\",\n",
    "    \"Kids\": \"Community & Social Impact\", \"Events\": \"Community & Social Impact\",\n",
    "    \"Residencies\": \"Community & Social Impact\", \"Workshops\": \"Community & Social Impact\",\n",
    "    \"Places\": \"Community & Social Impact\", \"Spaces\": \"Community & Social Impact\",\n",
    "    \"Makerspaces\": \"Community & Social Impact\",\n",
    "\n",
    "    # Nature & Miscellaneous\n",
    "    \"Animals\": \"Nature & Miscellaneous\", \"Nature\": \"Nature & Miscellaneous\", \"Taxidermy\": \"Nature & Miscellaneous\",\n",
    "    \"Flight\": \"Nature & Miscellaneous\", \"Immersive\": \"Nature & Miscellaneous\", \"Experimental\": \"Nature & Miscellaneous\",\n",
    "    \"Photography\": \"Nature & Miscellaneous\", \"Photo\": \"Nature & Miscellaneous\",\n",
    "    \"Photobooks\": \"Nature & Miscellaneous\", \"Architecture\": \"Nature & Miscellaneous\",\n",
    "}\n",
    "target_categories = [\n",
    "    \"Art & Design\",\n",
    "    \"Film, Video & Theater\",\n",
    "    \"Books, Writing & Publishing\",\n",
    "    \"Music\",\n",
    "    \"Technology & Software\",\n",
    "    \"Food & Drink\",\n",
    "    \"Fashion & Wearables\",\n",
    "    \"Games & Toys\",\n",
    "    \"Community & Social Impact\",\n",
    "    \"Nature & Miscellaneous\"\n",
    "]\n",
    "df[\"category_group\"] = df[\"category_name\"].map(category_mapping).fillna(\"Unknown\")\n",
    "df = df[df[\"category_group\"].isin(target_categories)].copy()\n",
    "n_per_class = df[\"category_group\"].value_counts().min()\n",
    "df = (\n",
    "    df.groupby(\"category_group\", group_keys=False)\n",
    "      .apply(lambda g: g.sample(n=n_per_class, random_state=42))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "rate = df[\"static_usd_rate\"].fillna(df[\"usd_exchange_rate\"]).astype(float).replace(0, np.nan)\n",
    "goal_usd = (df[\"goal\"].astype(float) * rate).replace([np.inf, -np.inf], np.nan)\n",
    "usd_pledged = df[\"usd_pledged\"].fillna(df.get(\"converted_pledged_amount\")).astype(float)\n",
    "\n",
    "valid = (goal_usd > 0) & usd_pledged.notna()\n",
    "sr_usd = pd.Series(np.nan, index=df.index, dtype=float)\n",
    "sr_usd[valid] = usd_pledged[valid] / goal_usd[valid]\n",
    "sr_usd = sr_usd.replace([np.inf, -np.inf], np.nan)\n",
    "df[\"success_ratio_usd\"] = sr_usd  # ← ตัวเดียว ใช้เป็นฐานให้ทั้งสองหัว\n",
    "\n",
    "# --- risk_level: tertile ต่อหมวด (กัน ties + กันหมวดเล็ก) ---\n",
    "def pooled_tertile(vals, groups=None, alpha=50, labels=(0,1,2)):\n",
    "    \"\"\"\n",
    "    vals   : pd.Series ของค่าที่จะจัดอันดับ (index ต้องตรงกับ groups)\n",
    "    groups : \n",
    "        - pd.Series ของกลุ่ม (ยาวเท่า vals), \n",
    "        - หรือ list/tuple ของ Series (จัดกลุ่มแบบหลายมิติ), \n",
    "        - หรือ None = ถือว่าเป็นกลุ่มเดียวทั้งหมด\n",
    "    alpha  : น้ำหนัก pooling กับ global CDF (กลุ่มเล็กจะพึ่ง global มากขึ้น)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # ทำความสะอาดค่า\n",
    "    v_all = pd.to_numeric(vals, errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "    out   = pd.Series(pd.NA, index=v_all.index, dtype=\"Int64\")\n",
    "    if v_all.notna().sum() == 0:\n",
    "        return out\n",
    "\n",
    "    # Global CDF\n",
    "    cdf_global = v_all.rank(method=\"average\", pct=True)\n",
    "\n",
    "    # เตรียมตัวแบ่งกลุ่ม\n",
    "    if groups is None:\n",
    "        by = pd.Series(0, index=v_all.index)             # กลุ่มเดียว\n",
    "    elif isinstance(groups, (list, tuple)):\n",
    "        # รองรับหลายมิติ (เช่น [df['category_group'], df['month_launched_at']])\n",
    "        by = [g.reindex(v_all.index) if isinstance(g, pd.Series) else pd.Series(g, index=v_all.index)\n",
    "              for g in groups]\n",
    "    else:\n",
    "        # เดี่ยว: ต้องเป็น Series ยาวเท่า vals\n",
    "        by = groups.reindex(v_all.index) if isinstance(groups, pd.Series) else pd.Series(groups, index=v_all.index)\n",
    "\n",
    "    # วิ่งทีละกลุ่ม\n",
    "    gb = v_all.groupby(by, dropna=False)\n",
    "    for key, idx in gb.groups.items():\n",
    "        v = v_all.loc[idx].dropna()\n",
    "        if v.empty:\n",
    "            continue\n",
    "        cdf_g   = v.rank(method=\"average\", pct=True)\n",
    "        w       = len(v) / (len(v) + alpha)  # กลุ่มใหญ่เชื่อค่ากลุ่มตัวเองมากขึ้น\n",
    "        cdf_star = w*cdf_g + (1-w)*cdf_global.loc[v.index]\n",
    "\n",
    "        out.loc[v.index] = pd.cut(\n",
    "            cdf_star, bins=[0, 1/3, 2/3, 1], labels=labels, include_lowest=True\n",
    "        ).astype(\"Int64\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "# เตรียมสเกลสำหรับทั้ง df (global)\n",
    "sr = np.log1p(\n",
    "    df[\"success_ratio_usd\"].clip(\n",
    "        lower=df[\"success_ratio_usd\"].quantile(0.01),\n",
    "        upper=df[\"success_ratio_usd\"].quantile(0.99)\n",
    "    )\n",
    ")\n",
    "\n",
    "# ทำ pooled tertile แบบหลายมิติ: category_group × month_launched_at\n",
    "df[\"risk_level\"] = pooled_tertile(\n",
    "    sr,\n",
    "    groups=[df[\"category_group\"], df[\"month_launched_at\"]],\n",
    "    alpha=50\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "baseline = df.groupby([\"category_group\"])[\"usd_pledged\"].median().rename(\"expected_pledge_baseline\")\n",
    "df = df.merge(baseline, on=\"category_group\", how=\"left\")\n",
    "df[\"goal_suitability_index\"] = (goal_usd / df[\"expected_pledge_baseline\"]).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "bins_goal = [-np.inf, 0.5, 2.0, np.inf]\n",
    "labels_goal = [0, 1, 2]   # 0=ต่ำไป, 1=พอเหมาะ, 2=สูงไป\n",
    "df[\"goal_eval\"] = pd.cut(df[\"goal_suitability_index\"], bins=bins_goal, labels=labels_goal).astype(\"Int64\")\n",
    "\n",
    "s = df[\"days_diff_state_changed_at_launched_at\"]\n",
    "df[\"duration_class\"] = pd.qcut(\n",
    "    s.rank(method=\"first\"),  # บังคับให้ลำดับไม่ชนกัน\n",
    "    q=4,\n",
    "    labels=[0,1,2,3]\n",
    ").astype(int)\n",
    "\n",
    "# 0) เตรียมสเกล (ถ้า success_rate เดิมเป็น % 0–100 ให้หาร 100)\n",
    "s = pd.to_numeric(df[\"success_rate\"], errors=\"coerce\").astype(float)\n",
    "s = s.clip(lower=0)                  # กันค่าติดลบ\n",
    "s = s / 100.0                        # <-- ถ้าเป็นเปอร์เซ็นต์\n",
    "s_log = np.log1p(s)                  # log(1+x) กันหางขวายาว\n",
    "\n",
    "bins  = [-np.inf, 50, 80, 100, 150, 300, np.inf]\n",
    "labels = [0, 1, 2, 3, 4, 5]\n",
    "df['success_rate_cls'] = pd.cut(df[\"percent_funded\"], bins=bins, labels=labels).astype('int64')\n",
    "# labels = [0, 1, 2, 3, 4, 5]\n",
    "# df['success_rate_cls'] = pd.qcut(\n",
    "#     df['percent_funded'],\n",
    "#     q=[0, .15, .30, .50, .70, .85, 1.0],   # ปรับเปอร์เซ็นไทล์ตามที่อยากบาลานซ์\n",
    "#     labels=labels, duplicates='drop'\n",
    "# ).astype('int64')\n",
    "\n",
    "\n",
    "df[\"goal_usd\"] = goal_usd\n",
    "df[\"goal_usd_log\"] = np.log1p(df[\"goal\"] * df[\"static_usd_rate\"])\n",
    "df[\"goal_per_day\"] = (df[\"goal_usd\"] / df[\"days_diff_launched_at_deadline\"])\n",
    "df[\"goal_per_day_log\"] = np.log1p(df[\"goal_per_day\"])\n",
    "\n",
    "grp = df.groupby(\"category_group\")\n",
    "df[\"gpd_rank_in_cat\"]      = grp[\"goal_per_day\"].rank(pct=True)\n",
    "df[\"gpd_vs_cat_median\"]    = df[\"goal_per_day\"] / grp[\"goal_per_day\"].transform(\"median\")\n",
    "df[\"gpd_dist_cat_median\"]  = (np.log(df[\"gpd_vs_cat_median\"].clip(lower=1e-9)) ).abs()  \n",
    "\n",
    "df[\"log1p_gpd_vs_cat_med\"] = np.log1p(df[\"gpd_vs_cat_median\"])\n",
    "\n",
    "df[\"goal_rank_in_cat\"]   = df.groupby(\"category_group\")[\"goal_usd\"].rank(pct=True)\n",
    "df[\"goal_vs_cat_median\"] = df[\"goal_usd\"] / df.groupby(\"category_group\")[\"goal_usd\"].transform(\"median\")\n",
    "df[\"goal_vs_country_median\"] = df[\"goal_usd\"] / df.groupby(\"country_displayable_name\")[\"goal_usd\"].transform(\"median\")\n",
    "\n",
    "# --- roundness of goal ---\n",
    "df[\"goal_round_100\"]  = ((df[\"goal_usd\"] % 100).abs()  < 1e-6).astype(\"int8\")\n",
    "df[\"goal_round_1000\"] = ((df[\"goal_usd\"] % 1000).abs() < 1e-6).astype(\"int8\")\n",
    "\n",
    "df[\"cat_freq\"]      = df[\"category_group\"].map(df[\"category_group\"].value_counts())\n",
    "df[\"country_freq\"]  = df[\"country_displayable_name\"].map(df[\"country_displayable_name\"].value_counts())\n",
    "cc = df[\"category_group\"].astype(str) + \"|\" + df[\"country_displayable_name\"].astype(str)\n",
    "df[\"cat_x_country_freq\"] = cc.map(cc.value_counts())\n",
    "df[\"cat_country_share\"] = df[\"cat_x_country_freq\"] / df[\"cat_freq\"].replace(0,1)\n",
    "\n",
    "# ratio = (\n",
    "#     pd.to_numeric(df[\"percent_funded\"], errors=\"coerce\")/100.0\n",
    "# ).fillna(\n",
    "#     pd.to_numeric(df[\"pledged\"], errors=\"coerce\") /\n",
    "#     pd.to_numeric(df[\"goal\"], errors=\"coerce\").replace(0, np.nan)\n",
    "# ).fillna(0.0).clip(lower=0.0)\n",
    "\n",
    "ratio = (pd.to_numeric(df[\"pledged\"], errors=\"coerce\") /\n",
    "    pd.to_numeric(df[\"goal\"], errors=\"coerce\").replace(0, np.nan)\n",
    ").fillna(0.0).clip(lower=0.0)\n",
    "# 1) near_miss_cls: 0=clear_fail, 1=near_miss, 2=success\n",
    "# df[\"near_miss_cls\"] = np.select(\n",
    "#     [ratio < 0.90, (ratio >= 0.90) & (ratio < 1.00), ratio >= 1.00],\n",
    "#     [0, 1, 2],\n",
    "#     default=0\n",
    "# ).astype(\"int8\")\n",
    "\n",
    "# 2) shortfall_severity_cls: 0=no_shortfall, 1=mild, 2=moderate, 3=severe\n",
    "df[\"shortfall_severity_cls\"] = np.select(\n",
    "    [ratio >= 1.00, (ratio >= 0.80) & (ratio < 1.00), (ratio >= 0.50) & (ratio < 0.80), ratio < 0.50],\n",
    "    [0, 1, 2, 3],\n",
    "    default=3\n",
    ").astype(\"int8\")\n",
    "\n",
    "# 3) stretch_potential_cls: 0=no_stretch, 1=light, 2=strong\n",
    "df[\"stretch_potential_cls\"] = np.select(\n",
    "    [ratio < 1.00, (ratio >= 1.00) & (ratio < 1.25), ratio >= 1.25],\n",
    "    [0, 1, 2],\n",
    "    default=0\n",
    ").astype(\"int8\")\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def eb_prior_oof(y, group_keys, alpha=50, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    y           : pd.Series (เช่น log1p(success_ratio_usd))\n",
    "    group_keys  : list of Series (เช่น [df['category_group'], df['month_launched_at']])\n",
    "    return      : pd.Series OOF-smoothed prior\n",
    "    \"\"\"\n",
    "    idx = y.index\n",
    "    gkey = pd.MultiIndex.from_arrays([g.reindex(idx) for g in group_keys])\n",
    "    prior = pd.Series(index=idx, dtype=float)\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for train_idx, valid_idx in kf.split(idx):\n",
    "        tr = idx[train_idx]; va = idx[valid_idx]\n",
    "        y_tr = y.loc[tr]\n",
    "        g_tr = gkey[train_idx]; g_va = gkey[valid_idx]\n",
    "\n",
    "        # สถิติกลุ่มจาก train fold เท่านั้น\n",
    "        cnt = pd.Series(1, index=tr).groupby(g_tr).sum()\n",
    "        sumy = y_tr.groupby(g_tr).sum()\n",
    "        mu  = y_tr.mean()\n",
    "\n",
    "        # EB smoothing\n",
    "        eb = (sumy + alpha*mu) / (cnt + alpha)\n",
    "\n",
    "        # map ไปที่ฝั่ง val\n",
    "        prior.loc[va] = eb.reindex(g_va).values\n",
    "\n",
    "    return prior\n",
    "\n",
    "# y = global target proxy สำหรับ prior\n",
    "y_sr = np.log1p(\n",
    "    df[\"success_ratio_usd\"].clip(df[\"success_ratio_usd\"].quantile(0.01),\n",
    "                                 df[\"success_ratio_usd\"].quantile(0.99))\n",
    ")\n",
    "\n",
    "df[\"prior_cat_mon_sr\"] = eb_prior_oof(\n",
    "    y=y_sr,\n",
    "    group_keys=[df[\"category_group\"], df[\"month_launched_at\"]],\n",
    "    alpha=50\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df.groupby([\"category_group\",\"month_launched_at\"])\n",
    "df[\"cat_mon_n\"]           = grp[\"goal_usd\"].transform(\"size\")\n",
    "df[\"cat_mon_goal_med\"]    = grp[\"goal_usd\"].transform(\"median\")\n",
    "df[\"cat_mon_gpd_med\"]     = grp[\"goal_per_day\"].transform(\"median\")\n",
    "df[\"gpd_rank_in_cat_mon\"] = grp[\"goal_per_day\"].rank(pct=True)\n",
    "df[\"goal_rank_in_cat_mon\"]= grp[\"goal_usd\"].rank(pct=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"goal_vs_cat_country_med\"] = df[\"goal_usd\"] / df.groupby(\n",
    "    [\"category_group\",\"country_displayable_name\"]\n",
    ")[\"goal_usd\"].transform(\"median\")\n",
    "\n",
    "df[\"gpd_vs_cat_country_med\"]  = df[\"goal_per_day\"] / df.groupby(\n",
    "    [\"category_group\",\"country_displayable_name\"]\n",
    ")[\"goal_per_day\"].transform(\"median\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สองหลักท้าย\n",
    "last2 = (df[\"goal_usd\"].round(0) % 100).fillna(-1).astype(int)\n",
    "df[\"goal_last2\"]    = last2\n",
    "df[\"goal_end_00\"]   = (last2 == 0).astype(\"int8\")\n",
    "df[\"goal_end_99\"]   = (last2 == 99).astype(\"int8\")\n",
    "df[\"goal_k_bucket\"] = np.floor(np.log10(df[\"goal_usd\"].clip(lower=1))).astype(\"Int64\")  # scale order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_28448\\2463628087.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  g2 = df.groupby([\"category_group\",\"dur_bin\"])\n"
     ]
    }
   ],
   "source": [
    "# บินระยะวันเป็นบินหยาบ ๆ\n",
    "dur_bin = pd.cut(df[\"days_diff_launched_at_deadline\"],\n",
    "                 bins=[-np.inf, 29, 45, 60, np.inf],\n",
    "                 labels=[\"<30\",\"30-45\",\"46-60\",\">60\"])\n",
    "df[\"dur_bin\"] = dur_bin.astype(\"category\")\n",
    "\n",
    "g2 = df.groupby([\"category_group\",\"dur_bin\"])\n",
    "df[\"gpd_rank_cat_dur\"]   = g2[\"goal_per_day\"].rank(pct=True)\n",
    "df[\"gpd_vs_catdur_med\"]  = df[\"goal_per_day\"] / g2[\"goal_per_day\"].transform(\"median\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เตรียมวัน\n",
    "df = df.sort_values(\"launched_at\").copy()\n",
    "df[\"day\"] = df[\"launched_at\"].dt.floor(\"D\")\n",
    "\n",
    "# นับจำนวน launch ต่อวันต่อหมวด (ได้ Series ที่มี MultiIndex: (category_group, day))\n",
    "daily = (df.groupby([\"category_group\", \"day\"])\n",
    "           .size()\n",
    "           .rename(\"launches\"))\n",
    "\n",
    "# กลุ่มละหมวด -> ดรอป level หมวดให้เหลือ index = day (DatetimeIndex)\n",
    "# เติมวันว่างเป็นรายวัน แล้ว rolling 30 วัน\n",
    "roll_30d = (daily\n",
    "            .groupby(level=0)                              # อย่าตั้ง group_keys=False\n",
    "            .apply(lambda s: s.droplevel(0)                # <— สำคัญ: เอา level หมวดออกก่อน\n",
    "                              .asfreq(\"D\", fill_value=0)   # เติมวันว่าง = 0\n",
    "                              .rolling(30, min_periods=1).sum())\n",
    "            .rename(\"cat_30d_launch_density\"))\n",
    "\n",
    "# map กลับเข้า df ด้วย MultiIndex (category_group, day)\n",
    "idx = pd.MultiIndex.from_frame(df[[\"category_group\", \"day\"]])\n",
    "df[\"cat_30d_launch_density\"] = roll_30d.reindex(idx).to_numpy()\n",
    "\n",
    "# ฟีเจอร์เสริมให้อ่านง่ายขึ้น (rank และ z-score ภายในหมวด)\n",
    "df[\"cat_30d_density_rank\"] = (\n",
    "    df.groupby(\"category_group\")[\"cat_30d_launch_density\"].rank(pct=True)\n",
    ")\n",
    "mu = df.groupby(\"category_group\")[\"cat_30d_launch_density\"].transform(\"mean\")\n",
    "sd = df.groupby(\"category_group\")[\"cat_30d_launch_density\"].transform(\"std\").replace(0, 1)\n",
    "df[\"cat_30d_density_z\"] = (df[\"cat_30d_launch_density\"] - mu) / sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prior_cat_mon_goal\"] = eb_prior_oof(\n",
    "    y=np.log1p(df[\"goal_usd\"]),\n",
    "    group_keys=[df[\"category_group\"], df[\"month_launched_at\"]],\n",
    "    alpha=30\n",
    ")\n",
    "df[\"goal_minus_prior_cat_mon\"] = np.log1p(df[\"goal_usd\"]) - df[\"prior_cat_mon_goal\"]\n",
    "\n",
    "df[\"prior_cat_country_mon_goal\"] = eb_prior_oof(\n",
    "    y=np.log1p(df[\"goal_usd\"]),\n",
    "    group_keys=[df[\"category_group\"], df[\"country_displayable_name\"], df[\"month_launched_at\"]],\n",
    "    alpha=50\n",
    ")\n",
    "df[\"goal_minus_prior_cat_country_mon\"] = np.log1p(df[\"goal_usd\"]) - df[\"prior_cat_country_mon_goal\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpd_vs_catdur_med\n",
       "0.000067        2\n",
       "0.000068        1\n",
       "0.000079        2\n",
       "0.000090        7\n",
       "0.000091        3\n",
       "               ..\n",
       "29377.775720    1\n",
       "30000.000000    2\n",
       "30965.137774    1\n",
       "33656.275797    1\n",
       "76338.173193    2\n",
       "Name: count, Length: 65859, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"gpd_vs_catdur_med\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique (with NA): [3 4 5 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "uniq_all = df[\"success_rate_cls\"].unique()\n",
    "print(\"unique (with NA):\", uniq_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧩 มีทั้งหมด 161 หมวดหมู่\n",
      "\n",
      " 1. 3D Printing\n",
      " 2. Academic\n",
      " 3. Accessories\n",
      " 4. Action\n",
      " 5. Animals\n",
      " 6. Animation\n",
      " 7. Anthologies\n",
      " 8. Apparel\n",
      " 9. Apps\n",
      "10. Architecture\n",
      "11. Art\n",
      "12. Art Books\n",
      "13. Audio\n",
      "14. Bacon\n",
      "15. Blues\n",
      "16. Calendars\n",
      "17. Camera Equipment\n",
      "18. Candles\n",
      "19. Ceramics\n",
      "20. Children's Books\n",
      "21. Childrenswear\n",
      "22. Chiptune\n",
      "23. Civic Design\n",
      "24. Classical Music\n",
      "25. Comedy\n",
      "26. Comic Books\n",
      "27. Comics\n",
      "28. Community Gardens\n",
      "29. Conceptual Art\n",
      "30. Cookbooks\n",
      "31. Country & Folk\n",
      "32. Couture\n",
      "33. Crafts\n",
      "34. Crochet\n",
      "35. DIY\n",
      "36. DIY Electronics\n",
      "37. Dance\n",
      "38. Design\n",
      "39. Digital Art\n",
      "40. Documentary\n",
      "41. Drama\n",
      "42. Drinks\n",
      "43. Electronic Music\n",
      "44. Embroidery\n",
      "45. Events\n",
      "46. Experimental\n",
      "47. Fabrication Tools\n",
      "48. Faith\n",
      "49. Family\n",
      "50. Fantasy\n",
      "51. Farmer's Markets\n",
      "52. Farms\n",
      "53. Fashion\n",
      "54. Festivals\n",
      "55. Fiction\n",
      "56. Film & Video\n",
      "57. Fine Art\n",
      "58. Flight\n",
      "59. Food\n",
      "60. Food Trucks\n",
      "61. Footwear\n",
      "62. Gadgets\n",
      "63. Games\n",
      "64. Gaming Hardware\n",
      "65. Glass\n",
      "66. Graphic Design\n",
      "67. Graphic Novels\n",
      "68. Hardware\n",
      "69. Hip-Hop\n",
      "70. Horror\n",
      "71. Illustration\n",
      "72. Immersive\n",
      "73. Indie Rock\n",
      "74. Installations\n",
      "75. Interactive Design\n",
      "76. Jazz\n",
      "77. Jewelry\n",
      "78. Journalism\n",
      "79. Kids\n",
      "80. Knitting\n",
      "81. Latin\n",
      "82. Letterpress\n",
      "83. Literary Journals\n",
      "84. Literary Spaces\n",
      "85. Live Games\n",
      "86. Makerspaces\n",
      "87. Metal\n",
      "88. Mixed Media\n",
      "89. Mobile Games\n",
      "90. Movie Theaters\n",
      "91. Music\n",
      "92. Music Videos\n",
      "93. Musical\n",
      "94. Narrative Film\n",
      "95. Nature\n",
      "96. Nonfiction\n",
      "97. Painting\n",
      "98. People\n",
      "99. Performance Art\n",
      "100. Performances\n",
      "101. Periodicals\n",
      "102. Pet Fashion\n",
      "103. Photo\n",
      "104. Photobooks\n",
      "105. Photography\n",
      "106. Places\n",
      "107. Playing Cards\n",
      "108. Plays\n",
      "109. Poetry\n",
      "110. Pop\n",
      "111. Pottery\n",
      "112. Print\n",
      "113. Printing\n",
      "114. Product Design\n",
      "115. Public Art\n",
      "116. Publishing\n",
      "117. Punk\n",
      "118. Puzzles\n",
      "119. Quilts\n",
      "120. R&B\n",
      "121. Radio & Podcasts\n",
      "122. Ready-to-wear\n",
      "123. Residencies\n",
      "124. Restaurants\n",
      "125. Robots\n",
      "126. Rock\n",
      "127. Romance\n",
      "128. Science Fiction\n",
      "129. Sculpture\n",
      "130. Shorts\n",
      "131. Small Batch\n",
      "132. Social Practice\n",
      "133. Software\n",
      "134. Sound\n",
      "135. Space Exploration\n",
      "136. Spaces\n",
      "137. Stationery\n",
      "138. Tabletop Games\n",
      "139. Taxidermy\n",
      "140. Technology\n",
      "141. Television\n",
      "142. Textiles\n",
      "143. Theater\n",
      "144. Thrillers\n",
      "145. Toys\n",
      "146. Translations\n",
      "147. Typography\n",
      "148. Vegan\n",
      "149. Video\n",
      "150. Video Art\n",
      "151. Video Games\n",
      "152. Wearables\n",
      "153. Weaving\n",
      "154. Web\n",
      "155. Webcomics\n",
      "156. Webseries\n",
      "157. Woodworking\n",
      "158. Workshops\n",
      "159. World Music\n",
      "160. Young Adult\n",
      "161. Zines\n"
     ]
    }
   ],
   "source": [
    "unique_categories = sorted(df[\"category_name\"].dropna().unique())\n",
    "print(f\"🧩 มีทั้งหมด {len(unique_categories)} หมวดหมู่\\n\")\n",
    "for i, cat in enumerate(unique_categories, 1):\n",
    "    print(f\"{i:>2}. {cat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_group\n",
       "Technology & Software          25312\n",
       "Books, Writing & Publishing    25312\n",
       "Games & Toys                   25312\n",
       "Music                          25312\n",
       "Art & Design                   25312\n",
       "Film, Video & Theater          25312\n",
       "Nature & Miscellaneous         25312\n",
       "Community & Social Impact      25312\n",
       "Fashion & Wearables            25312\n",
       "Food & Drink                   25312\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category_group\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n### 🎨 **Art & Design**\\n\\n* Art\\n* Fine Art\\n* Digital Art\\n* Illustration\\n* Mixed Media\\n* Painting\\n* Print\\n* Printing\\n* Graphic Design\\n* Typography\\n* Conceptual Art\\n* Installations\\n* Public Art\\n* Design\\n* Interactive Design\\n* Product Design\\n* Fashion\\n* Jewelry\\n* Pottery\\n* Ceramics\\n* Sculpture\\n* Textile\\n* Embroidery\\n* Weaving\\n* Knitting\\n* Crochet\\n* Stationery\\n* Letterpress\\n* Art Books\\n* Crafts\\n* DIY\\n* DIY Electronics\\n* Woodworking\\n* Candle\\n* Glass\\n* Metal\\n* Quilt\\n* Fabrication Tools\\n\\n---\\n\\n### 🎵 **Music**\\n\\n* Music\\n* Classical Music\\n* Electronic Music\\n* Hip-Hop\\n* Indie Rock\\n* Jazz\\n* Latin\\n* Pop\\n* Punk\\n* R\\\\&B\\n* Rock\\n* Blues\\n* World Music\\n* Sound\\n* Music Videos\\n* Audio\\n\\n---\\n\\n### 🎬 **Film, Video & Theater**\\n\\n* Film & Video\\n* Narrative Film\\n* Documentary\\n* Shorts\\n* Animation\\n* Video\\n* Video Art\\n* Video Games\\n* Television\\n* Theater\\n* Plays\\n* Performances\\n* Performance Art\\n* Musical\\n* Drama\\n* Comedy\\n* Horror\\n* Thrillers\\n* Webseries\\n\\n---\\n\\n### 📚 **Books, Writing & Publishing**\\n\\n* Books\\n* Children's Books\\n* Comic Books\\n* Comics\\n* Graphic Novels\\n* Cookbooks\\n* Poetry\\n* Fiction\\n* Nonfiction\\n* Romance\\n* Science Fiction\\n* Fantasy\\n* Anthologies\\n* Zines\\n* Literary Journals\\n* Literary Spaces\\n* Periodicals\\n* Translations\\n* Publishing\\n* Journalism\\n\\n---\\n\\n### 🕹️ **Games & Toys**\\n\\n* Games\\n* Tabletop Games\\n* Live Games\\n* Mobile Games\\n* Gaming Hardware\\n* Toys\\n* Playing Cards\\n* Puzzles\\n\\n---\\n\\n### 👗 **Fashion & Wearables**\\n\\n* Apparel\\n* Ready-to-wear\\n* Childrenswear\\n* Footwear\\n* Pet Fashion\\n* Accessories\\n* Wearables\\n* Couture\\n\\n---\\n\\n### 🍽️ **Food & Drink**\\n\\n* Food\\n* Drinks\\n* Food Trucks\\n* Vegan\\n* Small Batch\\n* Restaurants\\n* Bakeries\\n* Farmers Markets\\n* Farms\\n* Bacon\\n* Candles\\n\\n---\\n\\n### 🧠 **Technology & Software**\\n\\n* Apps\\n* Software\\n* Web\\n* Webcomics\\n* Webseries\\n* Robots\\n* Gadgets\\n* Camera Equipment\\n* Hardware\\n* Technology\\n* 3D Printing\\n* Space Exploration\\n\\n---\\n\\n### 🧑\\u200d🤝\\u200d🧑 **Community & Social Impact**\\n\\n* Community Gardens\\n* Social Practice\\n* Faith\\n* Civic Design\\n* Family\\n* People\\n* Kids\\n* Events\\n* Residencies\\n* Workshops\\n* Places\\n* Spaces\\n* Makerspaces\\n\\n---\\n\\n### 🐾 **Nature & Miscellaneous**\\n\\n* Animals\\n* Nature\\n* Taxidermy\\n* Flight\\n* Immersive\\n* Experimental\\n* Photography\\n* Photo\\n* Photobooks\\n* Architecture\\n\\n---\\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "### 🎨 **Art & Design**\n",
    "\n",
    "* Art\n",
    "* Fine Art\n",
    "* Digital Art\n",
    "* Illustration\n",
    "* Mixed Media\n",
    "* Painting\n",
    "* Print\n",
    "* Printing\n",
    "* Graphic Design\n",
    "* Typography\n",
    "* Conceptual Art\n",
    "* Installations\n",
    "* Public Art\n",
    "* Design\n",
    "* Interactive Design\n",
    "* Product Design\n",
    "* Fashion\n",
    "* Jewelry\n",
    "* Pottery\n",
    "* Ceramics\n",
    "* Sculpture\n",
    "* Textile\n",
    "* Embroidery\n",
    "* Weaving\n",
    "* Knitting\n",
    "* Crochet\n",
    "* Stationery\n",
    "* Letterpress\n",
    "* Art Books\n",
    "* Crafts\n",
    "* DIY\n",
    "* DIY Electronics\n",
    "* Woodworking\n",
    "* Candle\n",
    "* Glass\n",
    "* Metal\n",
    "* Quilt\n",
    "* Fabrication Tools\n",
    "\n",
    "---\n",
    "\n",
    "### 🎵 **Music**\n",
    "\n",
    "* Music\n",
    "* Classical Music\n",
    "* Electronic Music\n",
    "* Hip-Hop\n",
    "* Indie Rock\n",
    "* Jazz\n",
    "* Latin\n",
    "* Pop\n",
    "* Punk\n",
    "* R\\&B\n",
    "* Rock\n",
    "* Blues\n",
    "* World Music\n",
    "* Sound\n",
    "* Music Videos\n",
    "* Audio\n",
    "\n",
    "---\n",
    "\n",
    "### 🎬 **Film, Video & Theater**\n",
    "\n",
    "* Film & Video\n",
    "* Narrative Film\n",
    "* Documentary\n",
    "* Shorts\n",
    "* Animation\n",
    "* Video\n",
    "* Video Art\n",
    "* Video Games\n",
    "* Television\n",
    "* Theater\n",
    "* Plays\n",
    "* Performances\n",
    "* Performance Art\n",
    "* Musical\n",
    "* Drama\n",
    "* Comedy\n",
    "* Horror\n",
    "* Thrillers\n",
    "* Webseries\n",
    "\n",
    "---\n",
    "\n",
    "### 📚 **Books, Writing & Publishing**\n",
    "\n",
    "* Books\n",
    "* Children's Books\n",
    "* Comic Books\n",
    "* Comics\n",
    "* Graphic Novels\n",
    "* Cookbooks\n",
    "* Poetry\n",
    "* Fiction\n",
    "* Nonfiction\n",
    "* Romance\n",
    "* Science Fiction\n",
    "* Fantasy\n",
    "* Anthologies\n",
    "* Zines\n",
    "* Literary Journals\n",
    "* Literary Spaces\n",
    "* Periodicals\n",
    "* Translations\n",
    "* Publishing\n",
    "* Journalism\n",
    "\n",
    "---\n",
    "\n",
    "### 🕹️ **Games & Toys**\n",
    "\n",
    "* Games\n",
    "* Tabletop Games\n",
    "* Live Games\n",
    "* Mobile Games\n",
    "* Gaming Hardware\n",
    "* Toys\n",
    "* Playing Cards\n",
    "* Puzzles\n",
    "\n",
    "---\n",
    "\n",
    "### 👗 **Fashion & Wearables**\n",
    "\n",
    "* Apparel\n",
    "* Ready-to-wear\n",
    "* Childrenswear\n",
    "* Footwear\n",
    "* Pet Fashion\n",
    "* Accessories\n",
    "* Wearables\n",
    "* Couture\n",
    "\n",
    "---\n",
    "\n",
    "### 🍽️ **Food & Drink**\n",
    "\n",
    "* Food\n",
    "* Drinks\n",
    "* Food Trucks\n",
    "* Vegan\n",
    "* Small Batch\n",
    "* Restaurants\n",
    "* Bakeries\n",
    "* Farmers Markets\n",
    "* Farms\n",
    "* Bacon\n",
    "* Candles\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 **Technology & Software**\n",
    "\n",
    "* Apps\n",
    "* Software\n",
    "* Web\n",
    "* Webcomics\n",
    "* Webseries\n",
    "* Robots\n",
    "* Gadgets\n",
    "* Camera Equipment\n",
    "* Hardware\n",
    "* Technology\n",
    "* 3D Printing\n",
    "* Space Exploration\n",
    "\n",
    "---\n",
    "\n",
    "### 🧑‍🤝‍🧑 **Community & Social Impact**\n",
    "\n",
    "* Community Gardens\n",
    "* Social Practice\n",
    "* Faith\n",
    "* Civic Design\n",
    "* Family\n",
    "* People\n",
    "* Kids\n",
    "* Events\n",
    "* Residencies\n",
    "* Workshops\n",
    "* Places\n",
    "* Spaces\n",
    "* Makerspaces\n",
    "\n",
    "---\n",
    "\n",
    "### 🐾 **Nature & Miscellaneous**\n",
    "\n",
    "* Animals\n",
    "* Nature\n",
    "* Taxidermy\n",
    "* Flight\n",
    "* Immersive\n",
    "* Experimental\n",
    "* Photography\n",
    "* Photo\n",
    "* Photobooks\n",
    "* Architecture\n",
    "\n",
    "---\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"convert_json_data2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 253120 entries, 232880 to 154416\n",
      "Columns: 122 entries, backers_count to goal_minus_prior_cat_country_mon\n",
      "dtypes: Int64(3), bool(3), category(1), datetime64[ns](5), float64(57), int32(20), int64(11), int8(7), object(15)\n",
      "memory usage: 208.4+ MB\n",
      "253120\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        backers_count                                              blurb  \\\n",
      "0                  98  I make cool icons for iPhone developers at htt...   \n",
      "1                  98  I make cool icons for iPhone developers at htt...   \n",
      "2                  54  Postcards are fun to make, fun to send, and fu...   \n",
      "3                  54  Postcards are fun to make, fun to send, and fu...   \n",
      "4                  30  I'm a food and travel writer who fell into a j...   \n",
      "...               ...                                                ...   \n",
      "568065            112  Reissuing J. P. McEvoy's 1932 satirical novel ...   \n",
      "568066             34            Where deities daydream and runes speak.   \n",
      "568067             40                      A vinyl album of guitar music   \n",
      "568068              1                                    A Thrill Seeker   \n",
      "568069             54  Whiskered wonders return! Vol.2 brings delight...   \n",
      "\n",
      "        converted_pledged_amount country country_displayable_name  \\\n",
      "0                         1820.0      US        the United States   \n",
      "1                         1820.0      US        the United States   \n",
      "2                          626.0      US        the United States   \n",
      "3                          626.0      US        the United States   \n",
      "4                         1090.0      US        the United States   \n",
      "...                          ...     ...                      ...   \n",
      "568065                    2143.0      US        the United States   \n",
      "568066                    1949.0      US        the United States   \n",
      "568067                    2937.0      GB       the United Kingdom   \n",
      "568068                    1200.0      US        the United States   \n",
      "568069                    1190.0      US        the United States   \n",
      "\n",
      "                 created_at currency current_currency             deadline  \\\n",
      "0       2009-04-29 19:52:44      USD              USD  2009-06-15 19:00:00   \n",
      "1       2009-04-29 19:52:44      USD              USD  2009-06-15 19:00:00   \n",
      "2       2009-05-06 15:35:38      USD              USD  2009-07-01 05:00:00   \n",
      "3       2009-05-06 15:35:38      USD              USD  2009-07-01 05:00:00   \n",
      "4       2009-05-05 20:06:43      USD              USD  2009-07-14 14:00:00   \n",
      "...                     ...      ...              ...                  ...   \n",
      "568065  2025-07-01 20:05:24      USD              USD  2025-07-13 01:00:00   \n",
      "568066  2025-05-30 05:30:15      USD              USD  2025-07-13 17:49:30   \n",
      "568067  2025-06-06 10:14:26      GBP              USD  2025-07-06 21:00:00   \n",
      "568068  2025-06-27 18:03:20      USD              USD  2025-07-09 17:01:32   \n",
      "568069  2025-06-12 00:37:27      USD              USD  2025-07-10 21:44:51   \n",
      "\n",
      "         fx_rate  ...  gpd_rank_cat_dur gpd_vs_catdur_med         day  \\\n",
      "0       1.000000  ...          0.061795          0.057919  2009-04-29   \n",
      "1       1.000000  ...          0.061795          0.057919  2009-04-29   \n",
      "2       1.000000  ...          0.089933          0.089954  2009-05-06   \n",
      "3       1.000000  ...          0.089933          0.089954  2009-05-06   \n",
      "4       1.000000  ...          0.276923          0.416505  2009-05-09   \n",
      "...          ...  ...               ...               ...         ...   \n",
      "568065  1.000000  ...          0.518809          1.077300  2025-07-02   \n",
      "568066  1.000000  ...          0.573545          1.564997  2025-07-02   \n",
      "568067  1.348192  ...          0.776710          2.343668  2025-07-02   \n",
      "568068  1.000000  ...          0.575101          1.288889  2025-07-03   \n",
      "568069  1.000000  ...          0.298597          0.340856  2025-07-05   \n",
      "\n",
      "        cat_30d_launch_density cat_30d_density_rank  cat_30d_density_z  \\\n",
      "0                          2.0             0.000349          -1.646321   \n",
      "1                          2.0             0.000349          -1.646321   \n",
      "2                          2.0             0.000159          -1.660760   \n",
      "3                          2.0             0.000159          -1.660760   \n",
      "4                          1.0             0.000048          -1.083426   \n",
      "...                        ...                  ...                ...   \n",
      "568065                    95.0             0.149830          -0.744002   \n",
      "568066                   111.0             0.256321          -0.928321   \n",
      "568067                     8.0             0.001304          -2.627518   \n",
      "568068                    24.0             0.008138          -2.064546   \n",
      "568069                    82.0             0.125810          -1.011387   \n",
      "\n",
      "        prior_cat_mon_goal  goal_minus_prior_cat_mon  \\\n",
      "0                 8.875952                 -2.659346   \n",
      "1                 8.845286                 -2.628679   \n",
      "2                 7.758729                 -1.856095   \n",
      "3                 7.766794                 -1.864161   \n",
      "4                 8.074329                 -1.216815   \n",
      "...                    ...                       ...   \n",
      "568065            8.093537                 -1.159140   \n",
      "568066            7.970347                 -1.061592   \n",
      "568067            8.158051                 -0.931961   \n",
      "568068            8.420362                 -1.329452   \n",
      "568069            8.045105                 -3.439935   \n",
      "\n",
      "        prior_cat_country_mon_goal  goal_minus_prior_cat_country_mon  \n",
      "0                         9.020597                         -2.803991  \n",
      "1                         8.998237                         -2.781631  \n",
      "2                         7.884799                         -1.982166  \n",
      "3                         7.901798                         -1.999164  \n",
      "4                         8.165431                         -1.307917  \n",
      "...                            ...                               ...  \n",
      "568065                    8.146110                         -1.211713  \n",
      "568066                    8.344010                         -1.435255  \n",
      "568067                    7.936289                         -0.710199  \n",
      "568068                    8.604538                         -1.513628  \n",
      "568069                    8.427908                         -3.822738  \n",
      "\n",
      "[568070 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('convert_json_data.csv')\n",
    "df2 = pd.read_csv('convert_json_data2.csv')\n",
    "\n",
    "# รวมข้อมูลจากสองไฟล์\n",
    "df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# ตรวจสอบผลลัพธ์\n",
    "print(df_combined)\n",
    "df_combined.to_csv(\"convert_json_data_combined.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
